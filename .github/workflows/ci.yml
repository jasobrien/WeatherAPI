name: Weather API CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  DOTNET_VERSION: "8.0.x"
  JAVA_VERSION: "17"

jobs:
  build-and-unit-tests:
    name: Build and Unit Tests
    runs-on: ubuntu-latest

    steps:
      - name: 🛒 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: 📦 Restore dependencies
        run: dotnet restore

      - name: 🔨 Build solution
        run: dotnet build --configuration Release --no-restore

      - name: 🧪 Run unit tests
        run: |
          dotnet test test/WeatherAPI.UnitTests/WeatherAPI.UnitTests.csproj \
            --configuration Release \
            --no-build \
            --logger "trx;LogFileName=unit-test-results.trx" \
            --logger "console;verbosity=detailed" \
            --results-directory TestResults/UnitTests/ \
            --collect:"XPlat Code Coverage"

      - name: 📊 Upload unit test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: TestResults/UnitTests/

      - name: 📦 Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            src/WeatherAPI/bin/Release/
            test/*/bin/Release/

  specmatic-contract-tests:
    name: Specmatic Contract Tests
    runs-on: ubuntu-latest
    needs: build-and-unit-tests

    services:
      docker:
        image: docker:dind
        options: --privileged

    steps:
      - name: 🛒 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: ☕ Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: "temurin"
          java-version: ${{ env.JAVA_VERSION }}

      - name: 🐋 Setup Docker
        run: |
          sudo systemctl start docker
          sudo usermod -aG docker $USER

      - name: 📦 Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts

      - name: 🔧 Restore test dependencies
        run: dotnet restore test/WeatherAPI.AcceptanceTests/WeatherAPI.AcceptanceTests.csproj

      - name: 🧪 Run Specmatic contract validation
        run: |
          echo "🔍 Validating OpenAPI contract with Specmatic..."
          cd test/WeatherAPI.SpecmaticTests/contract

          # Pull Specmatic Docker image
          docker pull znsio/specmatic:latest

          # Validate contract syntax
          docker run --rm \
            -v "$(pwd):/usr/src/app" \
            -w /usr/src/app \
            znsio/specmatic:latest \
            validate weather-api-contract.yaml

      - name: 🧪 Run Specmatic stub tests
        run: |
          echo "🎭 Testing Specmatic stubs..."
          cd test/WeatherAPI.SpecmaticTests/contract

          # Start Specmatic stub server in background
          docker run --rm -d \
            --name specmatic-stub \
            -p 9003:9003 \
            -v "$(pwd):/usr/src/app" \
            -w /usr/src/app \
            znsio/specmatic:latest \
            stub weather-api-contract.yaml --port=9003 &
            
          # Wait for server to start
          sleep 10

          # Test basic endpoint availability
          curl -f http://localhost:9003/api/WeatherForecast?basic=true || echo "Warning: Basic endpoint test failed"
          curl -f http://localhost:9003/health || echo "Warning: Health endpoint test failed"

          # Stop the stub server
          docker stop specmatic-stub || true

      - name: 📊 Upload contract test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: specmatic-test-results
          path: test/WeatherAPI.SpecmaticTests/contract/

  acceptance-tests:
    name: Acceptance Tests with Reqnroll
    runs-on: ubuntu-latest
    needs: [build-and-unit-tests, specmatic-contract-tests]

    services:
      docker:
        image: docker:dind
        options: --privileged

    steps:
      - name: 🛒 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: ☕ Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: "temurin"
          java-version: ${{ env.JAVA_VERSION }}

      - name: 🐋 Setup Docker
        run: |
          sudo systemctl start docker
          sudo usermod -aG docker $USER

      - name: 📦 Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts

      - name: 🔧 Restore dependencies
        run: dotnet restore

      - name: 🔨 Build acceptance tests
        run: |
          dotnet build test/WeatherAPI.AcceptanceTests/WeatherAPI.AcceptanceTests.csproj \
            --configuration Release --no-restore

      - name: 🐳 Pull Specmatic Docker image
        run: docker pull znsio/specmatic:latest

      - name: 🧪 Run acceptance tests with HTML reports
        run: |
          cd test/WeatherAPI.AcceptanceTests

          echo "🚀 Running Weather API Acceptance Tests with HTML Report..."

          # Clean previous test results
          rm -rf TestResults/
          mkdir -p TestResults/

          # Make the test script executable
          chmod +x run-tests-with-report.sh

          # Run the tests with detailed logging and report generation
          dotnet test \
            --configuration Release \
            --logger "trx;LogFileName=TestResults.trx" \
            --logger "html;LogFileName=TestResults.html" \
            --logger "console;verbosity=detailed" \
            --results-directory TestResults/ \
            --collect:"XPlat Code Coverage" \
            --blame-hang-timeout 5m

      - name: 📊 Install ReportGenerator for enhanced reports
        run: |
          dotnet tool install --global dotnet-reportgenerator-globaltool --version 5.1.26 || true

      - name: 📈 Generate enhanced HTML reports
        if: always()
        run: |
          cd test/WeatherAPI.AcceptanceTests

          echo "📊 Generating enhanced HTML report..."

          # Find coverage files
          COVERAGE_FILES=$(find TestResults/ -name "*.cobertura.xml" -o -name "coverage.xml" | tr '\n' ';' | sed 's/;$//')

          if [ ! -z "$COVERAGE_FILES" ]; then
            reportgenerator \
              -reports:"$COVERAGE_FILES" \
              -targetdir:"TestResults/CoverageReport" \
              -reporttypes:"Html;Badges;TextSummary" \
              -title:"Weather API Acceptance Tests Coverage" \
              -tag:"${{ github.run_number }}" \
              -verbosity:Info
          else
            echo "⚠️ No coverage files found, skipping coverage report generation"
          fi

          # Generate test summary
          cat > TestResults/test-summary.html << 'EOF'
          <!DOCTYPE html>
          <html>
          <head>
              <title>Weather API Test Summary</title>
              <style>
                  body { font-family: Arial, sans-serif; margin: 20px; }
                  .header { background: #2e7d32; color: white; padding: 15px; border-radius: 5px; }
                  .section { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
                  .success { background: #e8f5e8; border-color: #4caf50; }
                  .info { background: #e3f2fd; border-color: #2196f3; }
                  .links { display: flex; gap: 10px; flex-wrap: wrap; }
                  .btn { 
                      display: inline-block; padding: 10px 15px; 
                      background: #1976d2; color: white; text-decoration: none; 
                      border-radius: 4px; margin: 5px 0;
                  }
                  .btn:hover { background: #1565c0; }
              </style>
          </head>
          <body>
              <div class="header">
                  <h1>🌤️ Weather API Test Results</h1>
                  <p>Build: ${{ github.run_number }} | Branch: ${{ github.ref_name }} | Commit: ${{ github.sha }}</p>
              </div>
              
              <div class="section success">
                  <h2>✅ Test Execution Complete</h2>
                  <p>All acceptance tests have been executed with Specmatic contract validation.</p>
                  <p><strong>Test Framework:</strong> Reqnroll (SpecFlow for .NET)</p>
                  <p><strong>Contract Testing:</strong> Specmatic with OpenAPI</p>
                  <p><strong>Generated:</strong> $(date)</p>
              </div>
              
              <div class="section info">
                  <h2>📊 Available Reports</h2>
                  <div class="links">
                      <a href="TestResults.html" class="btn">📝 Detailed Test Results</a>
                      <a href="CoverageReport/index.html" class="btn">📈 Coverage Report</a>
                      <a href="TestResults.trx" class="btn">📋 TRX Results</a>
                  </div>
              </div>
              
              <div class="section info">
                  <h2>🔧 Test Components</h2>
                  <ul>
                      <li><strong>Unit Tests:</strong> Weather service and controller validation</li>
                      <li><strong>Contract Tests:</strong> OpenAPI specification compliance with Specmatic</li>
                      <li><strong>Acceptance Tests:</strong> End-to-end behavior verification</li>
                      <li><strong>Integration Tests:</strong> Specmatic stub server integration</li>
                  </ul>
              </div>
          </body>
          </html>
          EOF

      - name: 📊 Upload acceptance test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: acceptance-test-results
          path: test/WeatherAPI.AcceptanceTests/TestResults/

      - name: 📊 Upload test reports to GitHub Pages
        uses: actions/upload-pages-artifact@v3
        if: always()
        with:
          path: test/WeatherAPI.AcceptanceTests/TestResults/

      - name: 📈 Publish test results
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: Acceptance Test Results
          path: test/WeatherAPI.AcceptanceTests/TestResults/*.trx
          reporter: dotnet-trx
          fail-on-error: true

  deploy-reports:
    name: Deploy Test Reports
    runs-on: ubuntu-latest
    needs: [acceptance-tests]
    if: always() && github.ref == 'refs/heads/main'

    permissions:
      pages: write
      id-token: write

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: 🚀 Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [build-and-unit-tests, specmatic-contract-tests, acceptance-tests]
    if: always()

    steps:
      - name: 📊 Generate workflow summary
        run: |
          echo "# 🌤️ Weather API Test Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results Overview" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Unit Tests Status
          if [ "${{ needs.build-and-unit-tests.result }}" == "success" ]; then
            echo "✅ **Unit Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Unit Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          # Contract Tests Status
          if [ "${{ needs.specmatic-contract-tests.result }}" == "success" ]; then
            echo "✅ **Contract Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Contract Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          # Acceptance Tests Status
          if [ "${{ needs.acceptance-tests.result }}" == "success" ]; then
            echo "✅ **Acceptance Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Acceptance Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 📋 Test Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- **Unit Test Results**: Available in artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- **Specmatic Contract Validation**: Available in artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- **Acceptance Test Reports**: Available in artifacts and GitHub Pages" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage Reports**: Generated with ReportGenerator" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 🔧 Pipeline Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **.NET Version**: ${{ env.DOTNET_VERSION }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Java Version**: ${{ env.JAVA_VERSION }} (for Specmatic)" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Framework**: Reqnroll + Specmatic" >> $GITHUB_STEP_SUMMARY
          echo "- **Contract Testing**: OpenAPI + Specmatic Stubs" >> $GITHUB_STEP_SUMMARY
